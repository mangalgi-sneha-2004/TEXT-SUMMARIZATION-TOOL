{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc161e7-57cd-480b-b73b-79c4c22d7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Article Summarization Tool ===\n",
      "Type 'exit' to quit at any time\n",
      "\n",
      "=== Sample Summary ===\n",
      "\n",
      "    Natural language processing (NLP) is a subfield of linguistics, computer science, \n",
      "    and artificial intelligence concerned with the interactions between computers and human language. It focuses on how to program computers to process and analyze large amounts of natural language data. The result is a computer capable of \"understanding\" the contents of documents, including the contextual \n",
      "    nuances of the language within them.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to summarize (min 10 words):\n",
      ">  Generative AI (Gen AI) refers to artificial intelligence systems capable of creating new content—such as text, images, music, or code—by learning patterns from vast datasets. Unlike traditional AI, which focuses on classification or prediction, Gen AI leverages advanced models like GPT-4, DALL·E, or Stable Diffusion to generate human-like outputs based on prompts. These models use deep learning architectures (e.g., transformers or diffusion models) trained on diverse data to produce contextually relevant and creative results. Applications range from content creation and software development to drug discovery and personalized education. However, challenges include ethical concerns (e.g., misinformation, bias) and the need for robust safeguards to ensure responsible use. Gen AI is revolutionizing industries by augmenting human creativity and automating complex tasks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary ===\n",
      "Generative AI (Gen AI) refers to artificial intelligence systems capable of creating new content—such as text, images, music, or code—by learning patterns from vast datasets. Unlike traditional AI, which focuses on classification or prediction, Gen AI leverages advanced models like GPT-4, DALL·E, or Stable Diffusion to generate human-like outputs based on prompts. These models use deep learning architectures (e.g., transformers or diffusion models) trained on diverse data to produce contextually relevant and creative results.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to summarize (min 10 words):\n",
      ">  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for using the summarizer!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from heapq import nlargest\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "# Download  NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "class ArticleSummarizer:\n",
    "    def __init__(self):\n",
    "        # Convert both to sets and use union operation\n",
    "        self.stop_words = set(stopwords.words('english')).union(set(punctuation))\n",
    "    \n",
    "    def summarize(self, text, num_sentences=3):\n",
    "        \"\"\"\n",
    "        Summarize the input text by extracting the most important sentences.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The input text to summarize\n",
    "            num_sentences (int): Number of sentences to include in summary\n",
    "            \n",
    "        Returns:\n",
    "            str: The generated summary\n",
    "        \"\"\"\n",
    "        # Tokenize  sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        if not sentences:  # Handle empty text\n",
    "            return \"No meaningful content to summarize.\"\n",
    "            \n",
    "        # Tokenize words and remove stopwords\n",
    "        words = word_tokenize(text.lower())\n",
    "        words = [word for word in words if word not in self.stop_words and word.isalnum()]\n",
    "        \n",
    "        # Calculate word frequencies\n",
    "        word_frequencies = FreqDist(words)\n",
    "        \n",
    "        # Calculate sentence scores \n",
    "        sentence_scores = defaultdict(int)\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            for word in word_tokenize(sentence.lower()):\n",
    "                if word in word_frequencies:\n",
    "                    sentence_scores[i] += word_frequencies[word]\n",
    "        \n",
    "        # Get the top N sentences\n",
    "        if not sentence_scores:  \n",
    "            return \" \".join(sentences[:num_sentences])\n",
    "            \n",
    "        top_sentence_indices = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "        top_sentence_indices.sort()  \n",
    "        \n",
    "        # Construct the summary\n",
    "        summary = ' '.join([sentences[i] for i in top_sentence_indices])\n",
    "        return summary\n",
    "\n",
    "def main():\n",
    "    print(\"=== Article Summarization Tool ===\")\n",
    "    print(\"Type 'exit' to quit at any time\\n\")\n",
    "    \n",
    "    summarizer = ArticleSummarizer()\n",
    "    \n",
    "    # Example usage\n",
    "    sample_text = \"\"\"\n",
    "    Natural language processing (NLP) is a subfield of linguistics, computer science, \n",
    "    and artificial intelligence concerned with the interactions between computers and human language. \n",
    "    It focuses on how to program computers to process and analyze large amounts of natural language data. \n",
    "    The result is a computer capable of \"understanding\" the contents of documents, including the contextual \n",
    "    nuances of the language within them. The technology can then accurately extract information and insights \n",
    "    contained in the documents as well as categorize and organize the documents themselves.\n",
    "    \n",
    "   \"\"\"\n",
    "    \n",
    "    print(\"=== Sample Summary ===\")\n",
    "    print(summarizer.summarize(sample_text))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "  \n",
    "    while True:\n",
    "        user_text = input(\"Enter text to summarize (min 10 words):\\n> \")\n",
    "        \n",
    "        if user_text.lower() == 'exit':\n",
    "            print(\"\\nThank you for using the summarizer!\")\n",
    "            break\n",
    "            \n",
    "        word_count = len(user_text.split())\n",
    "        if word_count < 10:\n",
    "            print(f\"Please enter at least 10 words (current: {word_count})\")\n",
    "            continue\n",
    "            \n",
    "        summary = summarizer.summarize(user_text)\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(summary)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d41eba-c603-4478-9d2c-eb0edef2a133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
